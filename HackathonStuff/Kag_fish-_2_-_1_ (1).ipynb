{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM 1 - OBJECT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.activations import softmax\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/univai-ss2019/uncategorized/runs/aasejf94\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "config = run.config\n",
    "config.img_width = 299\n",
    "config.img_height = 299\n",
    "config.epochs = 30\n",
    "config.batch_size = 16\n",
    "config.n_train_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3025 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "anno_classes = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF']\n",
    "train_data_dir = \"train\"\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,validation_split=0.2)\n",
    "\n",
    "# this is the augmentation configuration we will use for validation:\n",
    "# only rescaling\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir, \n",
    "        subset = 'training',\n",
    "        target_size = (config.img_width, config.img_height),\n",
    "        batch_size = config.batch_size,\n",
    "        shuffle = True,\n",
    "        classes = anno_classes,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 752 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir, \n",
    "        subset = 'validation',\n",
    "        target_size = (config.img_width, config.img_height),\n",
    "        batch_size = config.batch_size,\n",
    "        shuffle = True,\n",
    "        classes = anno_classes,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "conv_base = InceptionV3(include_top=False, weights='imagenet', input_shape=None)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(8,activation='softmax'))\n",
    "# model.add(Flatten(input_shape=conv_base.output_shape[1:]))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(8, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, None, None, 2048)  21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               204900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 808       \n",
      "=================================================================\n",
      "Total params: 22,008,492\n",
      "Trainable params: 21,974,060\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 192\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = get_nb_files(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3777"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1a43746f8b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nb_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dir' is not defined"
     ]
    }
   ],
   "source": [
    "nb_val_samples = get_nb_files(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node inception_v3/conv2d_3/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9eb7dfa20a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m752\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     callbacks=[WandbCallback()])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node inception_v3/conv2d_3/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=config.epochs,\n",
    "    steps_per_epoch=3025 // config.batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=752 // config.batch_size,\n",
    "    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 : Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = InceptionV3(include_top=False, weights='imagenet', input_shape=None)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(8,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "folders = glob.glob('train/*')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "anno_classes = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF']\n",
    "class_idx = list(range(0, 8))\n",
    "\n",
    "clas_dict = dict(zip(anno_classes, class_idx))\n",
    "\n",
    "\n",
    "records = []\n",
    "for folder in folders:\n",
    "    files = glob.glob(folder+\"/*.jpg\")\n",
    "    labels = [e.split('/')[1] for e in files]\n",
    "    train, valid = train_test_split(range(len(files)), test_size=0.2, random_state=1983)\n",
    "    mask = np.zeros(len(files))\n",
    "    for j in train:\n",
    "        mask[j] = 1\n",
    "    for i, label in enumerate(labels):\n",
    "        d = dict(label=clas_dict[label], file=files[i], train=mask[i])\n",
    "        records.append(d)\n",
    "import pandas as pd\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import json\n",
    "bb_json = {}\n",
    "anno_classes = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF']\n",
    "anno_classes1 = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft', 'NoF']\n",
    "class_idx = list(range(0, 8))\n",
    "\n",
    "clas_dict = dict(zip(anno_classes, class_idx))\n",
    "\n",
    "for c in anno_classes1:\n",
    "    j = json.load(open('bbox/{}_labels.json'.format(c), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]\n",
    "#print(bb_json.keys())\n",
    "count=0\n",
    "tot=0\n",
    "keys = bb_json.keys()\n",
    "records2 = []\n",
    "for r in records:\n",
    "    tot +=1\n",
    "    name = r['file'].split('/')[-1]\n",
    "    if not name in keys:\n",
    "        count += 1\n",
    "        #print(r['file'])\n",
    "        r['bbox'] = None\n",
    "    else:\n",
    "        bbox = bb_json[name]\n",
    "        r['x'] = bbox['x']\n",
    "        r['y'] = bbox['y']\n",
    "        r['width'] = bbox['width']\n",
    "        r['height'] = bbox['height']\n",
    "        records2.append(r)\n",
    "print(\"nobbox\", count, tot)\n",
    "print(\"rec5\", records2[:5])\n",
    "df = pd.DataFrame.from_records(records2)\n",
    "dftrain = df[df.train==1][['file', 'label', 'x', 'y', 'width', 'height']]\n",
    "dfvalid = df[df.train==0][['file', 'label', 'x', 'y', 'width', 'height']]\n",
    "\n",
    "dftrain.to_csv(\"tv_train.csv\", index=False, header=True)\n",
    "dfvalid.to_csv(\"tv_valid.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(299,299,3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base1 = InceptionV3(include_top=False, weights='imagenet', \n",
    "                         pooling='avg', input_shape=None)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Dense(100)(conv_base1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = Dense(8, activation='softmax', name='class_output')(backbone)\n",
    "y2 = Dense(4, activation='relu', name='bbox_output')(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input, outputs=[y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 2048)         21802784    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          204900      inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "class_output (Dense)            (None, 8)            808         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bbox_output (Dense)             (None, 4)            404         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,008,896\n",
      "Trainable params: 21,974,464\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #Keras - NHWC format / PyTorch - NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x= pd.read_csv('tv_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/SHARK/img_00478.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>497.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/SHARK/img_06913.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>501.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/SHARK/img_06410.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/SHARK/img_05873.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>588.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/SHARK/img_05399.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>538.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file  label      x      y  width  height\n",
       "0  train/SHARK/img_00478.jpg      5  497.0  364.0   70.0   123.0\n",
       "1  train/SHARK/img_06913.jpg      5  501.0  368.0   65.0   111.0\n",
       "2  train/SHARK/img_06410.jpg      5  372.0  575.0  630.0   169.0\n",
       "3  train/SHARK/img_05873.jpg      5  588.0  343.0   33.0   117.0\n",
       "4  train/SHARK/img_05399.jpg      5  538.0  364.0   78.0   129.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['file'] = x['file'].str.replace('train/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2408 images.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2)\n",
    "\n",
    "# this is the augmentation configuration we will use for validation:\n",
    "# only rescaling\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(x,\n",
    "        train_data_dir,\n",
    "        x_col = 'file' , y_col = ['label','x','y','width','height']  ,                                           \n",
    "        subset = 'training',\n",
    "        target_size = (config.img_width, config.img_height),\n",
    "        batch_size = config.batch_size,\n",
    "        shuffle = True,\n",
    "        classes = anno_classes,\n",
    "        class_mode = 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:194: UserWarning: `classes` will be ignored given the class_mode=\"other\"\n",
      "  .format(self.class_mode))\n"
     ]
    }
   ],
   "source": [
    "# valid_generator = train_datagen.flow_from_dataframe(x,\n",
    "#         train_data_dir,\n",
    "#         x_col = 'file' , y_col = ['label','x','y','width','height']  ,                                           \n",
    "#         subset = 'validation',\n",
    "#         target_size = (config.img_width, config.img_height),\n",
    "#         batch_size = config.batch_size,\n",
    "#         shuffle = True,\n",
    "#         classes = anno_classes,\n",
    "#         class_mode = 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 100* classification_loss + regression_log\n",
    "\n",
    "y_true - [class , x, y, h , w]\n",
    "y_pred - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-73e424bc8947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# get the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_fish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfish_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "# import keras.backend as K\n",
    "\n",
    "# def fish_loss():\n",
    "#     def custom(y_true, y_pred):\n",
    "#         true_label, predicted_label = y_true[0], y_pred[0]\n",
    "#         true_bbox, predicted_bbox = y_true[1:], y_pred[1:]\n",
    "#         return - (K.mean_squared_error(true_bbox, predicted_bbox) + \n",
    "#                   K.categorical_crossentropy(true_label, predicted_label))\n",
    "#     return custom\n",
    "# # Finally, you can use it as follows in Keras compile.\n",
    "\n",
    "# # build model \n",
    "\n",
    "\n",
    "# # get the loss function\n",
    "# model_fish = fish_loss(y_true, y_pred)\n",
    "\n",
    "# # compile model\n",
    "# model.compile(loss=model_fish,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "model.compile(loss={'class_output': 'sparse_categorical_crossentropy', 'bbox_output': 'mean_squared_error'},\n",
    "              loss_weights = {'class_output': 10, 'bbox_output': 1},\n",
    "              optimizer=RMSprop(lr=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = iter(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.7254902 , 0.76470596, 0.73333335],\n",
       "          [0.7372549 , 0.77647066, 0.74509805],\n",
       "          [0.7411765 , 0.7803922 , 0.7490196 ],\n",
       "          ...,\n",
       "          [0.26666668, 0.33333334, 0.3647059 ],\n",
       "          [0.25882354, 0.3254902 , 0.35686275],\n",
       "          [0.25882354, 0.3254902 , 0.35686275]],\n",
       " \n",
       "         [[0.7176471 , 0.7568628 , 0.7254902 ],\n",
       "          [0.7294118 , 0.7686275 , 0.7372549 ],\n",
       "          [0.7411765 , 0.7803922 , 0.7490196 ],\n",
       "          ...,\n",
       "          [0.26666668, 0.33333334, 0.3647059 ],\n",
       "          [0.26666668, 0.33333334, 0.3647059 ],\n",
       "          [0.26666668, 0.33333334, 0.3647059 ]],\n",
       " \n",
       "         [[0.7176471 , 0.7568628 , 0.7254902 ],\n",
       "          [0.7294118 , 0.7686275 , 0.7372549 ],\n",
       "          [0.7411765 , 0.7803922 , 0.7490196 ],\n",
       "          ...,\n",
       "          [0.2784314 , 0.33333334, 0.36862746],\n",
       "          [0.27058825, 0.3254902 , 0.36078432],\n",
       "          [0.27058825, 0.3254902 , 0.36078432]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.54509807, 0.5921569 , 0.5764706 ],\n",
       "          ...,\n",
       "          [0.28235295, 0.3372549 , 0.3803922 ],\n",
       "          [0.28235295, 0.3372549 , 0.3803922 ],\n",
       "          [0.2901961 , 0.34509805, 0.38823533]],\n",
       " \n",
       "         [[0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.54509807, 0.5921569 , 0.5764706 ],\n",
       "          ...,\n",
       "          [0.28235295, 0.3372549 , 0.37254903],\n",
       "          [0.28235295, 0.3372549 , 0.37254903],\n",
       "          [0.2901961 , 0.34509805, 0.3803922 ]],\n",
       " \n",
       "         [[0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.5372549 , 0.58431375, 0.5686275 ],\n",
       "          [0.54509807, 0.5921569 , 0.5764706 ],\n",
       "          ...,\n",
       "          [0.28235295, 0.3372549 , 0.37254903],\n",
       "          [0.28235295, 0.3372549 , 0.37254903],\n",
       "          [0.2901961 , 0.34509805, 0.3803922 ]]],\n",
       " \n",
       " \n",
       "        [[[0.37647063, 0.41176474, 0.40000004],\n",
       "          [0.19215688, 0.227451  , 0.21568629],\n",
       "          [0.21568629, 0.2509804 , 0.2392157 ],\n",
       "          ...,\n",
       "          [0.46274513, 0.227451  , 0.08627451],\n",
       "          [0.5019608 , 0.26666668, 0.1254902 ],\n",
       "          [0.48627454, 0.2509804 , 0.10980393]],\n",
       " \n",
       "         [[0.05490196, 0.09019608, 0.07843138],\n",
       "          [0.2509804 , 0.28627452, 0.27450982],\n",
       "          [0.21568629, 0.2509804 , 0.2392157 ],\n",
       "          ...,\n",
       "          [0.5686275 , 0.24705884, 0.10196079],\n",
       "          [0.56078434, 0.2392157 , 0.09411766],\n",
       "          [0.59607846, 0.27450982, 0.12941177]],\n",
       " \n",
       "         [[0.07450981, 0.10980393, 0.09803922],\n",
       "          [0.16078432, 0.19607845, 0.18431373],\n",
       "          [0.21568629, 0.2509804 , 0.2392157 ],\n",
       "          ...,\n",
       "          [0.58431375, 0.23529413, 0.0627451 ],\n",
       "          [0.6       , 0.2509804 , 0.07843138],\n",
       "          [0.6156863 , 0.26666668, 0.09411766]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.31764707, 0.3921569 , 0.36862746],\n",
       "          [0.3019608 , 0.37647063, 0.3529412 ],\n",
       "          [0.28627452, 0.36078432, 0.3372549 ],\n",
       "          ...,\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.15294118, 0.1764706 , 0.16862746]],\n",
       " \n",
       "         [[0.30588236, 0.3803922 , 0.35686275],\n",
       "          [0.33333334, 0.40784317, 0.38431376],\n",
       "          [0.33333334, 0.40784317, 0.38431376],\n",
       "          ...,\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.13725491, 0.16078432, 0.15294118]],\n",
       " \n",
       "         [[0.18431373, 0.25882354, 0.23529413],\n",
       "          [0.28627452, 0.36078432, 0.3372549 ],\n",
       "          [0.3137255 , 0.38823533, 0.3647059 ],\n",
       "          ...,\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.14509805, 0.16862746, 0.16078432],\n",
       "          [0.14509805, 0.16862746, 0.16078432]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 0.9921569 , 0.9686275 ],\n",
       "          [0.98823535, 1.        , 1.        ],\n",
       "          ...,\n",
       "          [0.97647065, 0.9803922 , 0.9490197 ],\n",
       "          [0.98823535, 1.        , 0.96470594],\n",
       "          [0.9803922 , 0.9921569 , 0.96470594]],\n",
       " \n",
       "         [[0.9960785 , 0.9960785 , 0.98823535],\n",
       "          [0.98823535, 0.9921569 , 1.        ],\n",
       "          [1.        , 0.9803922 , 0.9960785 ],\n",
       "          ...,\n",
       "          [0.9843138 , 1.        , 0.909804  ],\n",
       "          [0.9843138 , 1.        , 0.94117653],\n",
       "          [0.9725491 , 0.98823535, 0.9333334 ]],\n",
       " \n",
       "         [[1.        , 0.9921569 , 0.9725491 ],\n",
       "          [0.61960787, 0.6117647 , 0.62352943],\n",
       "          [1.        , 0.9058824 , 0.9490197 ],\n",
       "          ...,\n",
       "          [0.43529415, 0.47058827, 0.4039216 ],\n",
       "          [0.81568635, 0.854902  , 0.7607844 ],\n",
       "          [0.9607844 , 1.        , 0.8941177 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.28627452, 0.2627451 , 0.27058825],\n",
       "          [0.2901961 , 0.26666668, 0.26666668],\n",
       "          [0.3019608 , 0.2784314 , 0.2784314 ],\n",
       "          ...,\n",
       "          [0.26666668, 0.27058825, 0.24705884],\n",
       "          [0.26666668, 0.27058825, 0.24705884],\n",
       "          [0.2784314 , 0.28235295, 0.25882354]],\n",
       " \n",
       "         [[0.28235295, 0.25882354, 0.26666668],\n",
       "          [0.2784314 , 0.25490198, 0.25490198],\n",
       "          [0.29411766, 0.27058825, 0.27058825],\n",
       "          ...,\n",
       "          [0.2627451 , 0.26666668, 0.24313727],\n",
       "          [0.26666668, 0.27058825, 0.24705884],\n",
       "          [0.2784314 , 0.28235295, 0.25882354]],\n",
       " \n",
       "         [[0.2784314 , 0.25490198, 0.2627451 ],\n",
       "          [0.2784314 , 0.25490198, 0.25490198],\n",
       "          [0.29411766, 0.27058825, 0.27058825],\n",
       "          ...,\n",
       "          [0.2627451 , 0.26666668, 0.24313727],\n",
       "          [0.26666668, 0.27058825, 0.24705884],\n",
       "          [0.2784314 , 0.28235295, 0.25882354]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.6313726 , 0.6509804 , 0.627451  ],\n",
       "          [0.6117647 , 0.6313726 , 0.60784316],\n",
       "          [0.62352943, 0.6431373 , 0.61960787],\n",
       "          ...,\n",
       "          [0.5803922 , 0.6       , 0.6156863 ],\n",
       "          [0.5764706 , 0.59607846, 0.6117647 ],\n",
       "          [0.57254905, 0.5921569 , 0.60784316]],\n",
       " \n",
       "         [[0.63529414, 0.654902  , 0.6313726 ],\n",
       "          [0.62352943, 0.6431373 , 0.61960787],\n",
       "          [0.627451  , 0.64705884, 0.62352943],\n",
       "          ...,\n",
       "          [0.38431376, 0.40000004, 0.43529415],\n",
       "          [0.7372549 , 0.75294125, 0.78823537],\n",
       "          [0.5764706 , 0.5921569 , 0.627451  ]],\n",
       " \n",
       "         [[0.6313726 , 0.6509804 , 0.627451  ],\n",
       "          [0.627451  , 0.64705884, 0.62352943],\n",
       "          [0.6117647 , 0.6313726 , 0.60784316],\n",
       "          ...,\n",
       "          [0.454902  , 0.4666667 , 0.5254902 ],\n",
       "          [0.25882354, 0.27058825, 0.32941177],\n",
       "          [0.28235295, 0.29411766, 0.3529412 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.5019608 , 0.52156866, 0.53333336],\n",
       "          ...,\n",
       "          [0.4784314 , 0.47058827, 0.5137255 ],\n",
       "          [0.48235297, 0.4784314 , 0.50980395],\n",
       "          [0.5254902 , 0.52156866, 0.54509807]],\n",
       " \n",
       "         [[0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          ...,\n",
       "          [0.427451  , 0.41960788, 0.46274513],\n",
       "          [0.50980395, 0.5058824 , 0.5372549 ],\n",
       "          [0.5411765 , 0.5372549 , 0.56078434]],\n",
       " \n",
       "         [[0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          [0.49803925, 0.5176471 , 0.5294118 ],\n",
       "          ...,\n",
       "          [0.37647063, 0.36862746, 0.41176474],\n",
       "          [0.4901961 , 0.48627454, 0.5176471 ],\n",
       "          [0.5294118 , 0.5254902 , 0.54901963]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 0.9921569 , 0.9686275 ],\n",
       "          [0.98823535, 1.        , 1.        ],\n",
       "          ...,\n",
       "          [0.5058824 , 0.5882353 , 0.70980394],\n",
       "          [0.5647059 , 0.62352943, 0.7058824 ],\n",
       "          [0.5803922 , 0.6313726 , 0.69411767]],\n",
       " \n",
       "         [[0.9960785 , 0.9960785 , 0.98823535],\n",
       "          [0.98823535, 0.9921569 , 1.        ],\n",
       "          [1.        , 0.9803922 , 0.9960785 ],\n",
       "          ...,\n",
       "          [0.5058824 , 0.5882353 , 0.70980394],\n",
       "          [0.5568628 , 0.6156863 , 0.69803923],\n",
       "          [0.58431375, 0.63529414, 0.69803923]],\n",
       " \n",
       "         [[1.        , 0.9921569 , 0.9725491 ],\n",
       "          [0.61960787, 0.6117647 , 0.62352943],\n",
       "          [1.        , 0.9058824 , 0.9490197 ],\n",
       "          ...,\n",
       "          [0.50980395, 0.58431375, 0.7019608 ],\n",
       "          [0.5372549 , 0.6039216 , 0.6745098 ],\n",
       "          [0.58431375, 0.654902  , 0.7019608 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.22352943, 0.28627452, 0.34901962],\n",
       "          [0.21568629, 0.27450982, 0.35686275],\n",
       "          [0.20000002, 0.26666668, 0.36862746],\n",
       "          ...,\n",
       "          [0.22352943, 0.34901962, 0.54901963],\n",
       "          [0.16470589, 0.30588236, 0.5019608 ],\n",
       "          [0.16470589, 0.30980393, 0.5137255 ]],\n",
       " \n",
       "         [[0.2392157 , 0.3019608 , 0.3529412 ],\n",
       "          [0.23137257, 0.29411766, 0.35686275],\n",
       "          [0.20784315, 0.27450982, 0.37647063],\n",
       "          ...,\n",
       "          [0.2901961 , 0.38431376, 0.5176471 ],\n",
       "          [0.24313727, 0.3529412 , 0.5058824 ],\n",
       "          [0.20392159, 0.3137255 , 0.49803925]],\n",
       " \n",
       "         [[0.24313727, 0.30588236, 0.35686275],\n",
       "          [0.23529413, 0.29411766, 0.36862746],\n",
       "          [0.21176472, 0.2784314 , 0.3803922 ],\n",
       "          ...,\n",
       "          [0.22352943, 0.3254902 , 0.4156863 ],\n",
       "          [0.28627452, 0.38823533, 0.5254902 ],\n",
       "          [0.25882354, 0.3647059 , 0.53333336]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [1.        , 0.9921569 , 0.9686275 ],\n",
       "          [0.98823535, 1.        , 1.        ],\n",
       "          ...,\n",
       "          [0.00392157, 0.05882353, 0.00784314],\n",
       "          [0.00392157, 0.05882353, 0.00784314],\n",
       "          [0.00392157, 0.05882353, 0.00784314]],\n",
       " \n",
       "         [[0.9960785 , 0.9960785 , 0.98823535],\n",
       "          [0.98823535, 0.9921569 , 1.        ],\n",
       "          [1.        , 0.9803922 , 0.9960785 ],\n",
       "          ...,\n",
       "          [0.00392157, 0.05882353, 0.00784314],\n",
       "          [0.00392157, 0.05882353, 0.00784314],\n",
       "          [0.00392157, 0.05882353, 0.00784314]],\n",
       " \n",
       "         [[1.        , 0.9921569 , 0.9725491 ],\n",
       "          [0.61960787, 0.6117647 , 0.62352943],\n",
       "          [1.        , 0.9058824 , 0.9490197 ],\n",
       "          ...,\n",
       "          [0.        , 0.05882353, 0.01568628],\n",
       "          [0.        , 0.05882353, 0.01568628],\n",
       "          [0.        , 0.05882353, 0.01568628]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.20000002, 0.47450984, 0.227451  ],\n",
       "          [0.20784315, 0.48235297, 0.2392157 ],\n",
       "          [0.21960786, 0.49803925, 0.27058825],\n",
       "          ...,\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883]],\n",
       " \n",
       "         [[0.20392159, 0.4784314 , 0.23137257],\n",
       "          [0.21176472, 0.48627454, 0.24313727],\n",
       "          [0.22352943, 0.49411768, 0.27058825],\n",
       "          ...,\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883]],\n",
       " \n",
       "         [[0.21176472, 0.48627454, 0.2392157 ],\n",
       "          [0.21960786, 0.49411768, 0.2509804 ],\n",
       "          [0.227451  , 0.49803925, 0.27450982],\n",
       "          ...,\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883],\n",
       "          [0.00392157, 0.14117648, 0.04705883]]]], dtype=float32),\n",
       " array([[  7.        , 462.48      ,  60.63      , 290.46      ,\n",
       "         193.17      ],\n",
       "        [  0.        , 395.        ,  65.        , 200.        ,\n",
       "         119.        ],\n",
       "        [  0.        , 607.96631486, 351.48052578, 129.43032875,\n",
       "         146.05440767],\n",
       "        [  7.        , 194.73921023, 100.93190774,  91.43243407,\n",
       "         166.24078922],\n",
       "        [  6.        , 361.6449626 , 383.41063165, 224.35381939,\n",
       "         137.29114321],\n",
       "        [  0.        , 641.25009573, 478.844719  , 103.80549852,\n",
       "         170.7767879 ],\n",
       "        [  0.        , 213.06443603, 371.38899719, 112.0062055 ,\n",
       "          92.63671132],\n",
       "        [  0.        , 819.21      , 276.36      ,  64.86      ,\n",
       "          80.37      ],\n",
       "        [  6.        , 357.        ,  58.        , 487.        ,\n",
       "         196.        ],\n",
       "        [  6.        ,  66.        , 318.        , 212.        ,\n",
       "         235.        ],\n",
       "        [  0.        , 184.        , 307.        , 299.        ,\n",
       "         121.        ],\n",
       "        [  0.        , 374.04177574, 397.79045992, 146.05440767,\n",
       "          53.43453939],\n",
       "        [  1.        , 818.        , 269.        , 198.        ,\n",
       "         292.        ],\n",
       "        [  0.        , 388.        , 264.        , 243.        ,\n",
       "          74.        ],\n",
       "        [  0.        , 535.8       , 143.82      , 373.65      ,\n",
       "         150.87      ],\n",
       "        [  0.        , 461.91190719, 472.59881506, 159.11618397,\n",
       "          60.55914464]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 299, 299, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out[37][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 0., 0., 7., 6., 0., 0., 0., 6., 6., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out[37][1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[462.48      ,  60.63      , 290.46      , 193.17      ],\n",
       "       [395.        ,  65.        , 200.        , 119.        ],\n",
       "       [607.96631486, 351.48052578, 129.43032875, 146.05440767],\n",
       "       [194.73921023, 100.93190774,  91.43243407, 166.24078922],\n",
       "       [361.6449626 , 383.41063165, 224.35381939, 137.29114321],\n",
       "       [641.25009573, 478.844719  , 103.80549852, 170.7767879 ],\n",
       "       [213.06443603, 371.38899719, 112.0062055 ,  92.63671132],\n",
       "       [819.21      , 276.36      ,  64.86      ,  80.37      ],\n",
       "       [357.        ,  58.        , 487.        , 196.        ],\n",
       "       [ 66.        , 318.        , 212.        , 235.        ],\n",
       "       [184.        , 307.        , 299.        , 121.        ],\n",
       "       [374.04177574, 397.79045992, 146.05440767,  53.43453939],\n",
       "       [818.        , 269.        , 198.        , 292.        ],\n",
       "       [388.        , 264.        , 243.        ,  74.        ],\n",
       "       [535.8       , 143.82      , 373.65      , 150.87      ],\n",
       "       [461.91190719, 472.59881506, 159.11618397,  60.55914464]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out[37][1][:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[  0.        , 351.        , 439.        , 177.        ,\n         67.        ],\n       [  0.        , 757.        , 680.        , 424.        ,\n         70.        ],\n       [  3.        , 528...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-70c1682b0910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2405\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     callbacks=[WandbCallback()])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[  0.        , 351.        , 439.        , 177.        ,\n         67.        ],\n       [  0.        , 757.        , 680.        , 424.        ,\n         70.        ],\n       [  3.        , 528..."
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=config.epochs,\n",
    "    steps_per_epoch=2405 // config.batch_size,\n",
    "    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-cf6147e192a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'input_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0;34m'class_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bbox_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2405\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    {'input_1': train_generator[0]},\n",
    "    {'class_output': train_generator[1][:,0], 'bbox_output': train_generator[1][:,1:]},\n",
    "    epochs=config.epochs,\n",
    "    steps_per_epoch=2405 // config.batch_size,\n",
    "    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = iter(train_generator)\n",
    "g1 = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150/150 [==============================] - 125s 833ms/step - loss: 103673.6774 - class_output_loss: 3.9405 - bbox_output_loss: 103634.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 62680.0119 - class_output_loss: 3.3234 - bbox_output_loss: 62646.7783\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 28697.5404 - class_output_loss: 2.8610 - bbox_output_loss: 28668.9302\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 2311.2270 - class_output_loss: 2.0492 - bbox_output_loss: 2290.7346\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 204.1265 - class_output_loss: 1.1015 - bbox_output_loss: 193.1113\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 44.5119 - class_output_loss: 1.0122 - bbox_output_loss: 34.3901\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 33.2876 - class_output_loss: 1.0102 - bbox_output_loss: 23.1852\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 27.8825 - class_output_loss: 1.0094 - bbox_output_loss: 17.7886\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 24.3195 - class_output_loss: 1.0089 - bbox_output_loss: 14.2306\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 22.1261 - class_output_loss: 1.0086 - bbox_output_loss: 12.0403\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 20.5130 - class_output_loss: 1.0084 - bbox_output_loss: 10.4292\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 19.2581 - class_output_loss: 1.0082 - bbox_output_loss: 9.1761\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 18.2474 - class_output_loss: 1.0081 - bbox_output_loss: 8.1666\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 17.5771 - class_output_loss: 1.0080 - bbox_output_loss: 7.4971\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 16.8765 - class_output_loss: 1.0079 - bbox_output_loss: 6.7973\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 16.4340 - class_output_loss: 1.0079 - bbox_output_loss: 6.3555\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 15.8779 - class_output_loss: 1.0078 - bbox_output_loss: 5.7998\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 100s 664ms/step - loss: 15.4842 - class_output_loss: 1.0078 - bbox_output_loss: 5.4066\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 15.2021 - class_output_loss: 1.0077 - bbox_output_loss: 5.1249\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 14.9139 - class_output_loss: 1.0077 - bbox_output_loss: 4.8370\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 14.6341 - class_output_loss: 1.0077 - bbox_output_loss: 4.5575\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 14.4416 - class_output_loss: 1.0076 - bbox_output_loss: 4.3652\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 14.2396 - class_output_loss: 1.0076 - bbox_output_loss: 4.1634\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 14.0397 - class_output_loss: 1.0076 - bbox_output_loss: 3.9638\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 13.9010 - class_output_loss: 1.0076 - bbox_output_loss: 3.8252\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 13.7210 - class_output_loss: 1.0076 - bbox_output_loss: 3.6453\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 13.5593 - class_output_loss: 1.0076 - bbox_output_loss: 3.4838\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 99s 663ms/step - loss: 13.4907 - class_output_loss: 1.0075 - bbox_output_loss: 3.4153\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 13.3129 - class_output_loss: 1.0075 - bbox_output_loss: 3.2376\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 99s 662ms/step - loss: 13.2639 - class_output_loss: 1.0075 - bbox_output_loss: 3.1887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2c5d3d0f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'input_4': g1[0]},\n",
    "    {'class_output': g1[1][:,0], 'bbox_output': g1[1][:,1:]},\n",
    "    epochs=config.epochs,\n",
    "    steps_per_epoch=2405 // config.batch_size,\n",
    "    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all batches.\n",
    "# Go for multiple epochs\n",
    "# conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
